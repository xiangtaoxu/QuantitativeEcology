{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "extreme-zoning",
   "metadata": {},
   "source": [
    "# BIOEE 4940 : **Introduction to Quantitative Analysis in Ecology**\n",
    "### ***Spring 2021***\n",
    "### Instructor: **Xiangtao Xu** ( ✉️ xx286@cornell.edu)\n",
    "### Teaching Assistant: **Yanqiu (Autumn) Zhou** (✉️ yz399@cornell.edu)\n",
    "\n",
    "---\n",
    "\n",
    "## <span style=\"color:royalblue\">Lecture 2</span> *How to Describe Your Data: a revisit to probability and distributions*\n",
    "*Partly adapted from [How to be a quantitative ecologist](https://www.researchgate.net/publication/310239832_How_to_be_a_Quantitative_Ecologist_The_'A_to_R'_of_Green_Mathematics_and_Statistics) and [All of Statistics](https://www.stat.cmu.edu/~larry/all-of-statistics/)*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-latex",
   "metadata": {},
   "source": [
    "### 1. Data, Process, and Probability\n",
    "\n",
    "Statistics play a pivotal role in quantitative analysis in real world data because the observationas we collected are usually composite of a series of deterministic and stochastic processes. In statistics, probability theory helps us to undersatnd how these processes interact to generate samples/data we can see, while inversely, statistical inference helps us to parse **signal** out from **noise** and gain knowledge about the deterministic processes and the invariant properties of the stochastic processes.\n",
    "\n",
    "<img src=\"./img/Probability_and_inference.png\" alt=\"Probability and Inference\" style=\"width: 800px;\"/>\n",
    "\n",
    "*Source: All of Statistics*\n",
    "\n",
    "\n",
    "* **Discussion**: Suppose we got samples on the 15min-average flying speed of birds from gps trackers. What are possible data generating processes? How would signal and noise change with different research targets? (Image From: news.cornell.edu)\n",
    "\n",
    "<img src=\"https://news.cornell.edu/sites/default/files/styles/story_thumbnail_xlarge/public/2018-01/0123_tags_0.jpg?h=ebb7e033&itok=FGuLXHhl\" alt=\"Solar-powered tracker\" style=\"width: 200px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-measure",
   "metadata": {},
   "source": [
    "#### 1.1. Definition of Probability\n",
    "Probability is a mathematical language for quantifying uncertainty for data generating processes.\n",
    "\n",
    "We need a few more concepts before a rigorous definition of property:\n",
    "\n",
    "* *Experiment*: A repeatable data collection process that has a well-defined possible outcomes\n",
    "* *Events*: Collections of experimental outcomes\n",
    "* *Event/sample space*: All possible outcomes from an experiment\n",
    "\n",
    "<img src=\"./img/Venn_diagram.png\" alt=\"Venn Diagram for different relationships between events\" style=\"width: 800px;\"/>\n",
    "\n",
    "*Source: How to be a quantitative ecologist*\n",
    "\n",
    "\n",
    "* *Probability* is non-negative real number associated with each event that reflects the *frequency* (Frequentist) or *degree of beliefs* (Bayesian) of the events.\n",
    "* An idealistic but intuitive frequentist definition, $p = \\lim_{N \\to \\infty} \\frac{n}{N}$ where N is the total number of trials and n is the counts of trials with the target event."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-speaking",
   "metadata": {},
   "source": [
    "* **Example**: Sampling tree density from a tropical moist forest at Barro Colorado Island, Panama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-caribbean",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# first read data\n",
    "\n",
    "df_bci = pd.read_excel('./data/bci_census.xlsx')\n",
    "# a 200 m by 500 m quadrat of the whole census (10 Ha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-discussion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the plot\n",
    "\n",
    "# only show trees > 50cm\n",
    "\n",
    "df_plot = df_bci[df_bci['dbh'] >= 500.]\n",
    "\n",
    "from matplotlib.patches import Circle\n",
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "fig, ax= plt.subplots(1,1,figsize=(3,6))\n",
    "\n",
    "# prepare circles to represent each tree\n",
    "# we use a 5 m radius circule to represent a 500mm dbh tree\n",
    "# we use a 25 m radius circle to represent a 2000mm dbh tree\n",
    "patches = [Circle((tree['gx'],tree['gy']),radius=(tree['dbh'] - 500.) / 1500. * 20. + 5.,\n",
    "                   color='xkcd:forest green'\n",
    "                  )\n",
    "           for index, tree in df_plot.iterrows()]\n",
    "p = PatchCollection(patches, facecolor='xkcd:forest green',alpha=0.8)\n",
    "ax.add_collection(p)\n",
    "\n",
    "ax.set_xlim((0.,200.))\n",
    "ax.set_ylim((0.,500.))\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample the probability of finding at least 1 50cm+ tree in a 5-by-5 meter quadrat\n",
    "\n",
    "# record 1000 sampling\n",
    "sample_N = 1000\n",
    "\n",
    "site_x = 200.\n",
    "site_y = 500.\n",
    "quadrat_size = 5.\n",
    "\n",
    "# sample the upper left corner of the quadrat\n",
    "# I used a legacy style, the newest numpy has some updated functions \n",
    "# check https://numpy.org/doc/stable/reference/random/index.html#module-numpy.random\n",
    "np.random.RandomState() # generate a random seed\n",
    "sample_x = np.random.sample(sample_N) * (site_x - quadrat_size)\n",
    "sample_y = np.random.sample(sample_N) * (site_y - quadrat_size)\n",
    "\n",
    "tree_number = [df_plot[\n",
    "    (df_plot['gx'] >= x) & (df_plot['gx'] < x + quadrat_size)\n",
    "   &(df_plot['gy'] >= y) & (df_plot['gy'] < y + quadrat_size)].count()['treeID'] >= 1\n",
    "               for x, y in zip(sample_x,sample_y)\n",
    "    ]\n",
    "\n",
    "prob = np.cumsum(tree_number) / np.arange(1,sample_N+1)\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(np.arange(1,sample_N+1),prob)\n",
    "ax.set_xlabel('# of trials')\n",
    "ax.set_ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-barbados",
   "metadata": {},
   "source": [
    "#### 1.2 Quantitative Properties of Probabilities\n",
    "\n",
    "* Union and Intersection\n",
    "\n",
    "<img src=\"./img/probability_addition.png\" alt=\"Probability Addition\" style=\"width: 800px;\"/>\n",
    "\n",
    "*Source: How to be a quantitative ecologist*\n",
    "\n",
    "$P(A \\cup B) = P(A) + P(B) - P(A \\cap B)$ \\[commonly abbreviated as $P(AB)$\\]\n",
    "\n",
    "* Conditional Probability and Independent Events\n",
    "\n",
    "Often, the probability that an event E2 occurs is affected by the prior occurrence of another event E1\n",
    "\n",
    "<img src=\"./img/conditional_probability.png\" alt=\"Conditional Probability\" style=\"width: 800px;\"/>\n",
    "*Source: How to be a quantitative ecologist*\n",
    "\n",
    "\n",
    "In this case, we define the conditional probability of E2 given E1 as\n",
    "$P(E_2 | E_1) = \\frac{P(E_{1}E_{2})}{P(E_1)}$\n",
    "\n",
    "We can also derive **Bayes' law** from the definition:\n",
    "$P(E_2 | E_1) = \\frac{P(E_{1} | E_{2})P(E_2)}{P(E_1)}$\n",
    "\n",
    "\n",
    "E1 and E2 are considered independent if $P(E_{1}E_{2}) = P(E_1)P(E_2)$. In this case $P(E_2 | E_1) = P(E_2)$\n",
    "\n",
    "* Discussion: Field census in tropical forests requires tracking a large number of species. Someone proposes to replace the usage of a 4-character code (e.g. POTR) with a new 6-digit code (e.g. POSTRE) to avoid code conflicts for species with similar initials. This proposal receives some criticism in terms of increasing typo errors. Could you explain this criticism from a probability point of view?\n",
    "\n",
    "* Example: Probabiliy of species and size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-bumper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare event A: finding a tree of species cecrin and event B: finding a 20+cm tree in a 5-by-5 meter quadrat\n",
    "sample_N = 1000\n",
    "\n",
    "site_x = 200.\n",
    "site_y = 500.\n",
    "quadrat_size = 5.\n",
    "\n",
    "# sample the upper left corner of the quadrat\n",
    "np.random.RandomState() # generate a random seed\n",
    "sample_x = np.random.sample(sample_N) * (site_x - quadrat_size)\n",
    "sample_y = np.random.sample(sample_N) * (site_y - quadrat_size)\n",
    "\n",
    "\n",
    "event_A = [df_bci[\n",
    "    (df_bci['gx'] >= x) & (df_bci['gx'] < x + quadrat_size)\n",
    "   &(df_bci['gy'] >= y) & (df_bci['gy'] < y + quadrat_size)\n",
    "   &(df_bci['sp'] == 'cecrin')].count()['treeID'] >= 1\n",
    "               for x, y in zip(sample_x,sample_y)\n",
    "    ]\n",
    "\n",
    "event_B = [df_bci[\n",
    "    (df_bci['gx'] >= x) & (df_bci['gx'] < x + quadrat_size)\n",
    "   &(df_bci['gy'] >= y) & (df_bci['gy'] < y + quadrat_size)\n",
    "   &(df_bci['dbh'] >= 100.)\n",
    "   ].count()['treeID'] >= 1.\n",
    "               for x, y in zip(sample_x,sample_y)\n",
    "    ]\n",
    "\n",
    "event_AB = [df_bci[\n",
    "    (df_bci['gx'] >= x) & (df_bci['gx'] < x + quadrat_size)\n",
    "   &(df_bci['gy'] >= y) & (df_bci['gy'] < y + quadrat_size)\n",
    "   &(df_bci['sp'] == 'cecrin') & (df_bci['dbh'] >= 100.)].count()['treeID'] >= 1\n",
    "               for x, y in zip(sample_x,sample_y)\n",
    "    ]\n",
    "\n",
    "# convert to numpy arrays for easier indexing\n",
    "event_A = np.array(event_A)\n",
    "event_B = np.array(event_B)\n",
    "event_AB = np.array(event_AB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-bouquet",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_A = sum(event_A) / sample_N\n",
    "P_B = sum(event_B) / sample_N\n",
    "P_AB = sum(event_AB) / sample_N\n",
    "P_A_bar_B = sum(event_AB[event_B > 0]) / sum(event_B > 0)\n",
    "P_B_bar_A = sum(event_AB[event_A > 0]) / sum(event_A > 0)\n",
    "print(f'P(A) = {P_A}, P(B) = {P_B}, P(AB) = {P_AB}, P(A)*P(B)={P_A * P_B}')\n",
    "print(f'P(A|B) = {P_A_bar_B}, P(AB)/P(B) = {P_AB / P_B}')\n",
    "print(f'P(B|A) = {P_B_bar_A}, P(AB)/P(A) = {P_AB / P_A}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-gazette",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. Random variable and Probability distribution\n",
    "\n",
    "In reality, we are often concerned with the observable values of the event space of an experiment, which are usually called as **random variables** or statistical variables.\n",
    "\n",
    "\n",
    "<img src=\"./img/statistical_variables.png\" alt=\"Classification of Statistical Variables\" style=\"width: 800px;\"/>\n",
    "\n",
    "*Source: How to be a quantitative ecologist*\n",
    "\n",
    "\n",
    "In addition, we usually seek to obtain a probability associated with every possible value across the event space, i.e. **probability distribution**.\n",
    "    \n",
    "* For discrete variables, we can define a *probability mass function* (PMF) as $f_X(x) = P(X=x)$ and *cumulate distribution function* (CDF) as $F_X(x) = P(X \\leq x)$\n",
    "* For continuous variables, it is straightforward to first define the CDF as $F_X(x) = P(X \\leq x)$ and then a *probability density function* (PDF) as $f_X(x) = \\frac{dF_X(x)}{dx}$. PDFs have the following key mathematical properties:\n",
    "    * $CDF(x) = \\int_{-\\infty}^{x} PDF(x) \\,dx$\n",
    "    * $P(a < X \\leq b) = \\int_{a}^{b} PDF(x) \\,dx$\n",
    "    * $\\int_{-\\infty}^{\\infty} PDF(x) \\,dx = 1$\n",
    "    \n",
    "* Example from tree size distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-pricing",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,1,figsize=(3,6))\n",
    "\n",
    "# plot frequency\n",
    "df_bci.plot(y='dbh',kind='hist',bins=np.linspace(0,1000,100),density=False,ax=ax[0])\n",
    "\n",
    "# get an approximation of PDF by dividing probability with bin size.\n",
    "df_bci.plot(y='dbh',kind='hist',bins=np.linspace(0,1000,100),density=True,ax=ax[1])\n",
    "\n",
    "# CDF\n",
    "df_bci.plot(y='dbh',kind='hist',bins=np.linspace(0,1000,100),density=True,cumulative=True,ax=ax[2])\n",
    "\n",
    "ax[2].set_xlabel('DBH (mm)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-inventory",
   "metadata": {},
   "source": [
    "#### 2.1 Descriptive statistics\n",
    "\n",
    "For a given distribution, there are several basic metrics to describe its pattern and property:\n",
    "* mean (arithmetric average, useful for spatio-temporal upscaling of quasi-linear processes)\n",
    "* mode (peaks among distribution, useful to identify centrality of the distribution)\n",
    "* range (max - min, some information on variability at the extreme scenario)\n",
    "* percentiles (common to show in a box-whisker plot, more information on variability and the eveness of the sample distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-cincinnati",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bci.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-schedule",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_bci['sp'].mode())\n",
    "print(df_bci[df_bci['dbh'] > 200.]['sp'].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_bci['sp'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-mailing",
   "metadata": {},
   "source": [
    "Additional characteristics of distributions can be more formally decrived using the concept of **expectation**. Generally, the expected value of a certain function of a random variable is defined as\n",
    "\n",
    "$E(g(x)) = \\int_{-\\infty}^{\\infty}g(x)PDF(x)\\,dx$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-victoria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the distribution for the # of neighbouring trees within 20 by 20 meter window of a focal tree.\n",
    "# only count trees with 20cm+ dbh to reduce computation time\n",
    "\n",
    "df_20cm = df_bci[df_bci['dbh'] >= 200.]\n",
    "\n",
    "window_size = 20.\n",
    "\n",
    "neighbour_num = [df_20cm[\n",
    "    (df_20cm['gx'] >= tree['gx'] - window_size / 2.)\n",
    "   &(df_20cm['gx'] <  tree['gx'] + window_size / 2.)\n",
    "   &(df_20cm['gy'] >= tree['gy'] - window_size / 2.)\n",
    "   &(df_20cm['gy'] <  tree['gy'] + window_size / 2.)\n",
    "    ].count()['treeID'] for i, tree in df_20cm.iterrows()]\n",
    "df_20cm['N_num'] = neighbour_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-farmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_num_diff = df_20cm['N_num'].values - np.nanmean(df_20cm['N_num'].values)\n",
    "df_20cm['N_num_p1'] = N_num_diff\n",
    "df_20cm['N_num_p2'] = N_num_diff ** 2\n",
    "df_20cm['N_num_p3'] = N_num_diff ** 3\n",
    "df_20cm['N_num_p4'] = N_num_diff ** 4\n",
    "\n",
    "plot_names = [f'N_num_p{p}' for p in range(1,4+1)]\n",
    "fig, axes = plt.subplots(2,2,figsize=(6,6))\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    df_20cm.plot(y=plot_names[i],kind='hist',ax=ax,density=True)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-barbados",
   "metadata": {},
   "source": [
    "The expections, produced by raising the values of the variable to integer powers are known as the **moments of the distribution**:\n",
    "* First order moment -> mean, $\\mu = E(X)$\n",
    "* Second order moment -> variance, $Var(X) = E(X^2) - E(X)^2$\n",
    "* Third order moment -> skewness (whether the distribution is symmetrical)\n",
    "* Fourth order momoent -> kurtosis (how peaked a distribution is)\n",
    "\n",
    "Useful properties of expectations:\n",
    "* $E(A+B) = E(A) + E(B)$ where A, B are two random variables\n",
    "* $E(kA) = kE(A)$ where k is a constant\n",
    "* For independent random variables, $E(AB) = E(A)E(B)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-gentleman",
   "metadata": {},
   "source": [
    "#### 2.2 Common theoretical distributions\n",
    "There are a few extensively studied probability distributions that can come handy to model/approximate different types of randomness. In this lecture, we will learn some basic distributions, which we will revisit in future topics like regression analysis. We will also save some more complex distributions such as t-distribution, F-distribution, and chi-square distribution later when we talk about statistical inferences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-mother",
   "metadata": {},
   "source": [
    "* Uniform distribution\n",
    "\n",
    "$f(x) = \\frac{1}{b-a}$\n",
    "\n",
    "e.g. the distribution of X location of each tree as shown below.\n",
    "\n",
    "Useful to generate numerical sampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-threshold",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example, the distribution of the X-coordinate of trees in BCI is quasi-uniform\n",
    "# suggeting the spatial tree distribution is relatively homogenous\n",
    "\n",
    "df_bci[df_bci['gx'] <= 150].plot(y='gx',kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-figure",
   "metadata": {},
   "source": [
    "* Bernoulli distribution\n",
    "\n",
    "The simplest experiment that has one of only two outcomes. Hit or miss, survival or death, success or failure, ....\n",
    "\n",
    "$f(x) = p^xq^{1-x}$ where $q = 1 - p$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-police",
   "metadata": {},
   "source": [
    "* Binomial distribution\n",
    "\n",
    "The probability of a certain number of occurrence during a series of independent Bernoulli trials\n",
    "\n",
    "$f(x) = {n \\choose x}p^xq^{n-x}$, where n is the total number of trials, p is the success rate as in the Bernoulli distribution, q = 1 - p.\n",
    "\n",
    "For a Binomial distribution $\\mu = np$, and $\\sigma^2=npq$\n",
    "\n",
    "Bernoulli and Binomial distributions are useful to model counting (occurrance) or demographic processes (birth and death)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-problem",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "# randomly select 20 trees from the forest\n",
    "# what is the probability of having x number\n",
    "# of 10cm+ trees?\n",
    "\n",
    "sample_N = 500\n",
    "select_N = 20\n",
    "tree_size = 100\n",
    "\n",
    "result = [ sum(df_bci.sample(select_N)['dbh'] > tree_size)\n",
    "          for i in range(sample_N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "ax.hist(result,bins=range(select_N+1),align='left',density=True,\n",
    "        label='observed')\n",
    "\n",
    "ax.set_xlabel('# of 10cm+ trees')\n",
    "ax.set_ylabel('PDF')\n",
    "\n",
    "ax.set_xticks(range(0,20,2))\n",
    "\n",
    "# compare with theoretical distribution\n",
    "mean=np.nanmean(result) # average number of trees found\n",
    "var=np.nanvar(result) # variance\n",
    "print(f'mean (np): {mean}')\n",
    "print(f'var (npq): {var}')\n",
    "p = mean / select_N\n",
    "print(f'p = {mean / select_N}')\n",
    "from scipy.stats import binom\n",
    "\n",
    "# define the random variable\n",
    "rv = binom(select_N,p)\n",
    "x = range(select_N+1)\n",
    "ax.plot(x,rv.pmf(x),'r-o',label='theoretical')\n",
    "\n",
    "ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-interstate",
   "metadata": {},
   "source": [
    "* Poisson Distribution\n",
    "\n",
    "Numer of occurrences in a unit of time or space\n",
    "\n",
    "$f(x) = \\frac{e^{-\\lambda}\\lambda^x}{x!}$, where $\\lambda$ is a rate parameter.\n",
    "\n",
    "The mean and variance of the distributions are both $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-potential",
   "metadata": {},
   "outputs": [],
   "source": [
    "# revisit tree density distribution\n",
    "\n",
    "# tree density can be viewed as the 'rate' \n",
    "# of occurrence in space\n",
    "\n",
    "# If you are 'walking' along the Y-direction in the forest plot\n",
    "# what is the probability distribution of # of 1+cm tree within\n",
    "# the 1m band of your walking path?\n",
    "\n",
    "walking_x = 30. # a random selection\n",
    "\n",
    "sample_Y = range(500) # maximum length of Y-direction\n",
    "\n",
    "result = [\n",
    "    df_bci[\n",
    "        (df_bci['gx'] >= walking_x - 0.5)\n",
    "       &(df_bci['gx'] <  walking_x + 0.5)\n",
    "       &(df_bci['gy'] >= y) \n",
    "       &(df_bci['gy'] <  y + 1.)\n",
    "    ].count()['treeID'] for y in sample_Y\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "ax.hist(result,bins=range(10),align='left',density=True,\n",
    "        label='observed')\n",
    "\n",
    "ax.set_xlabel('# of 5cm+ trees')\n",
    "ax.set_ylabel('PDF')\n",
    "\n",
    "# compare with theoretical distribution\n",
    "mean=np.nanmean(result) # average number of trees found\n",
    "var=np.nanvar(result) # variance\n",
    "print(f'mean (lambda): {mean}')\n",
    "print(f'var (lambda): {var}')\n",
    "lambda_val = (mean + var) / 2.\n",
    "from scipy.stats import poisson\n",
    "\n",
    "# define the random variable\n",
    "rv = poisson(lambda_val)\n",
    "x = range(10)\n",
    "ax.plot(x,rv.pmf(x),'r-o',label='theoretical')\n",
    "\n",
    "ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-technician",
   "metadata": {},
   "source": [
    "* Geometric distribution, Negative Binomial distribution, Exponential distribution, and Gamma distribution\n",
    "\n",
    "    All distributions can be interpreted as the probability of *waiting time*.\n",
    "\n",
    "    * Geometric distribution describes the number of trials until *next* success.\n",
    "\n",
    "    $f(x)=pq^{x-1}$ with mean as $1/p$, and variance as $q/p^2$\n",
    "\n",
    "    * Negative binomial distribution describes the number of trials until *k* successes occur\n",
    "\n",
    "    $f(x) = {x-1 \\choose k-1}p^kq^{x-k}$ with mean value as $k/p$ and variance as $kq/p^2$\n",
    "\n",
    "    Exponential and Gamma distribution can be interpreted as counter-parts for continuous variables\n",
    "    \n",
    "    * Exponential distribution describes the waiting time/distance until the next occurrence of the event.\n",
    "    \n",
    "    $f(x) = {\\lambda}e^{-{\\lambda}x}$, where $\\lambda$ is the rate of occurrence. The distribution has a mean value of $1/\\lambda$ and variance of $1/\\lambda^2$\n",
    "    \n",
    "    * Gamma distribution decribes the waiting time/distance until the kth occurrence of the event.\n",
    "    \n",
    "    $f(x) = x^{k-1}{\\lambda}^k\\frac{e^{-{\\lambda}x}}{\\Gamma(k)}$, with a mean value of $k/\\lambda$ and variance of $k/\\lambda^2$. Here $\\Gamma(x)$ is called the gamma function, which can be viewed as a continuous version of integer factorial.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-butterfly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional after-class challenge: linking exponential and poisson distribution\n",
    "\n",
    "# Consider the same forest 'walk' we had above, count the distance bewteen each\n",
    "# encounter of a 20cm+ tree, examine its distribution and compare it with a \n",
    "# theoretical Poisson distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-hours",
   "metadata": {},
   "source": [
    "* Beta distribution\n",
    "\n",
    "Beta distribution is a continuous distribution between 0 and 1 with two parameters, which allows for flexible fitting to any distributions. This is quite useful to set prior distribution in Bayesian analysis.\n",
    "\n",
    "$f(x) = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}x^{(\\alpha-1)}(1-x)^{\\beta-1}$, where 0 < x < 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-still",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of the shapes of beta distributions\n",
    "# note that to make the interactive plot work, you need to install ipywidgets using the following conda commands:\n",
    "# conda install ipywidgets\n",
    "# conda install nodejs\n",
    "# jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "\n",
    "# remember to update your jupyterlab to the newest version\n",
    "# check https://ipywidgets.readthedocs.io/en/latest/user_install.html for more details\n",
    "\n",
    "from scipy.stats import beta\n",
    "from ipywidgets import interactive\n",
    "\n",
    "\n",
    "\n",
    "# define a plotting fuction\n",
    "def plot_beta(alpha_val,beta_val):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    plot_x = np.arange(0.001,1,0.001)\n",
    "    \n",
    "    plot_y = beta.pdf(plot_x,alpha_val,beta_val)\n",
    "    #label = f'a={alpha_val},b={beta_val}'\n",
    "    ax.plot(plot_x,plot_y)\n",
    "    \n",
    "    ax.set_ylim([0,3])\n",
    "    \n",
    "    #ax.legend(loc='upper center')\n",
    "    plt.show()\n",
    "\n",
    "interactive_plot = interactive(plot_beta, \n",
    "                               alpha_val=(0.1, 5,0.1), \n",
    "                               beta_val=(0.1, 5, 0.1))\n",
    "\n",
    "# show the interactive plot\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-blair",
   "metadata": {},
   "source": [
    "* Normal (Gaussian) distribution, the central limit theorem, and log-Normal distribution\n",
    "\n",
    "    * Normal distribution is probably the most requently used probability distribution in quantitative analysis. It has a bell-shaped, symmetric PDF. $f(x)=\\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{1}{2}\\frac{(\\mu-x)^2}{\\sigma^2}}$, where $\\mu$ represents the mean and $\\sigma^2$ represents the variance. Usually we call the normal distribution with a mean of zero and a variance of 1 as *standard normal distributions*\n",
    "\n",
    "    * The **central limit theorem** is a strong and important result in statistics. It states that the *sum of many independent, identically distributed* random variables (no matter what kind of distribution they are from) is normally distributed with mean as $N\\mu$ and variance as $N\\sigma^2$, where N indicates the number of variables, $\\mu$ and $\\sigma^2$ denotes the mean and variance of each random variable. CLT is one of the cornerstones of inferential statistics and the reason why normally distribtued variables are so prevalent in nature.\n",
    "\n",
    "    * If a random process consists of multipilcation of many independent and identically distributed random variables, we can infer from CLT that the logarithm of the process (convert product to sum) converges to a normal distribution. We can call the process as **lognormally distributed**. Like Gamma distribution, log-normal distribution is only defined for non-negative values and has a PDF as:\n",
    "\n",
    "    $f(x)=\\frac{1}{x\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{(lnx-\\mu)^2}{2\\sigma^2}}$. Here, $\\mu$ and $\\sigma^2$ denotes the mean and variance of the *log-transformed* normal distribution. The mean and variance of X is\n",
    "\n",
    "    $E(X)=e^{\\mu+\\frac{1}{2}\\sigma^2}$ and $var(X)=(e^{\\sigma^2}-1)e^{2\\mu+\\sigma^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of average DBH\n",
    "\n",
    "# First, the distribution of DBH within the forest plot is not normally distributed\n",
    "fig, ax = plt.subplots(1,1)\n",
    "df_bci.plot(y='dbh',kind='hist',density=True,bins=np.arange(10,510+1,5), ax=ax)\n",
    "ax.set_ylabel('Probability Density')\n",
    "plt.show()\n",
    "df_bci['dbh'].describe() # show mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-wheel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's randomly sample N trees and calculate the average dbh\n",
    "# Do this for 1000 times\n",
    "sample_N = 1000\n",
    "\n",
    "# let's try 10 trees first ...\n",
    "tree_N = 10\n",
    "\n",
    "dbh_avg = np.array([df_bci['dbh'].sample(tree_N).mean(skipna=True)\n",
    "               for i in range(sample_N)])\n",
    "\n",
    "# now let's plot the distribution of dbh_avg\n",
    "mu = np.mean(dbh_avg)\n",
    "std = np.std(dbh_avg)\n",
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "ax.hist(dbh_avg,bins=np.arange(0,100,1),align='left',density=True,\n",
    "        label=f'N={tree_N},mu={mu:4.2f},sqrt(N)*std={std*(tree_N**0.5):4.2f}')\n",
    "\n",
    "# overlay a theoretical normal distribution\n",
    "from scipy.stats import norm\n",
    "rv = norm(loc=np.mean(dbh_avg),scale=std)\n",
    "plot_x = np.arange(0,100,1)\n",
    "ax.plot(plot_x,rv.pdf(plot_x),'r-o',label = 'theoretical')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-intelligence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log-normal distribution\n",
    "# distribution of tree density of every 10-by-10 meter sub-quadrat\n",
    "# We can view the distribution of a stochastic recruitment process\n",
    "\n",
    "# Assume initial density is N0 for all sub-qudrat, \n",
    "# each year the net relative recruitment rate is a random variable (1 + r)\n",
    "# r could be positive or negative\n",
    "# After T years, N(T) = N0*(1+r1)*(1+r2)*...(1+rT)\n",
    "# If N0 is constant, N(T) would be a lognormally distributed variable.\n",
    "\n",
    "quadrat_size = 10.\n",
    "quadrats = [] # record upper left corner of each quadrat\n",
    "for i, x in enumerate(np.arange(0,150,quadrat_size)):\n",
    "    for j, y in enumerate(np.arange(0,500,quadrat_size)):\n",
    "        quadrats.append((x,y))\n",
    "        \n",
    "density = [ df_bci[\n",
    "        (df_bci['gx'] >= q[0] )\n",
    "       &(df_bci['gx'] <  q[0] + quadrat_size)\n",
    "       &(df_bci['gy'] >= q[1]) \n",
    "       &(df_bci['gy'] <  q[1] + quadrat_size)\n",
    "    ].count()['treeID'] / quadrat_size**2 for q in quadrats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-hawaiian",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1)\n",
    "\n",
    "ax[0].hist(density,align='left',density=True,bins=40)\n",
    "mu = np.mean(density)\n",
    "std = np.std(density)\n",
    "\n",
    "# overlay a theoretical normal distribution\n",
    "rv = norm(loc=mu,scale=std)\n",
    "plot_x = np.linspace(np.amin(density),np.amax(density),20)\n",
    "ax[0].plot(plot_x,rv.pdf(plot_x),'r-o')\n",
    "\n",
    "\n",
    "ax[1].hist(np.log(density),align='left',density=True,bins=40)\n",
    "mu = np.mean(np.log(density))\n",
    "std = np.std(np.log(density))\n",
    "\n",
    "# overlay a theoretical normal distribution\n",
    "rv = norm(loc=mu,scale=std)\n",
    "plot_x = np.linspace(np.amin(np.log(density)),np.amax(np.log(density)),20)\n",
    "ax[1].plot(plot_x,rv.pdf(plot_x),'r-o')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-jungle",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "1. Probability links processes with observations.\n",
    "2. Quantitative properties of probabilities (conditional prob. and independent events)\n",
    "3. Common discrete and continuous probability distributions and their interpretations\n",
    "4. Central limit theorem (sum of random processes) and log-normal distribution (product of random processes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-federation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
